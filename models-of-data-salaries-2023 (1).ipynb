{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing Random Forest and Keras Models on a Categorical Dataset with Continuous Target Variable\n\n## Introduction\n\nIn this project, we are comparing the initial performance of a Random Forest model to that of a Keras neural network. We will evaluate the performance of both models using common regression metrics such as the Root Mean Squared Error (RMSE), R-squared, and Out-Of-Bag (OOB) score. By comparing the performance of these models, we aim to determine which one is better suited for the given task and potentially identify areas for improvement in both models.","metadata":{}},{"cell_type":"markdown","source":"## Dataset\nThis dataset is sourced from listings on ai-jobs.net and was updated within a month of this notebook's creation and can be found at https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023","metadata":{}},{"cell_type":"code","source":"salaries_df = pd.read_csv('../input/data-science-salaries-2023/ds_salaries.csv')\nsalaries_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dropping salary and salary_currency \nWe can use the salary_in_usd instead of these two since they are not standardized for all data points ","metadata":{}},{"cell_type":"code","source":"salaries_df = salaries_df.drop('salary', axis=1)\nsalaries_df = salaries_df.drop('salary_currency', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting categorical data into dummy coding format for model\n\nTo use categorical data in our regression model, we need to convert it into numerical format. One way to do this is by using dummy coding. \n\nWe will create dummy variables for the following categorical features:\n- `job_title`\n- `employment_type`\n- `employee_residence`\n- `company_location`\n- `company_size`\n- `experience_level`\n\nDummy coding involves creating a new binary column for each unique value in a categorical feature. If a row belongs to a certain category, the corresponding binary column will have a value of 1, otherwise it will have a value of 0. \n\nWe will use the `pandas` `get_dummies` function to create our dummy variables. \n\n\n","metadata":{}},{"cell_type":"code","source":"dummy_df = pd.get_dummies(salaries_df[['experience_level', 'employment_type', 'job_title','employee_residence','company_location','company_size']], prefix=['exp','time', 'job','resd','loc','size'])\ndummy_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clearing catagorial features\nNow that we have dummy coded our features we do not need them in the dataset ","metadata":{}},{"cell_type":"code","source":"filtered_salaries_df = pd.concat([salaries_df, dummy_df], axis=1)\nfiltered_salaries_df = filtered_salaries_df.drop(['experience_level', 'employment_type', 'job_title','employee_residence','company_location','company_size'], axis=1)\nfiltered_salaries_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random forest model \nThen, we train a random forest regressor model with 100 estimators and an out-of-bag score of True, which will enable us to have another metric of performance outside of RMSE and R score ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(filtered_salaries_df.drop('salary_in_usd', axis=1), filtered_salaries_df['salary_in_usd'], random_state=1)\n\n# Train a random forest regressor model\nn_estimators = 800  # number of trees in the forest\nmax_depth = 300   # maximum depth of each decision tree\nmin_samples_split = 2 # minimum number of samples required to split an internal node\nmin_samples_leaf = 1   # minimum number of samples required to be at a leaf node\n\n# Create the Random Forest model with the desired hyperparameters\nrf = RandomForestRegressor(\n    n_estimators=n_estimators,\n    oob_score=True,\n    max_depth=max_depth,\n    min_samples_split=min_samples_split,\n    min_samples_leaf=min_samples_leaf,\n    random_state=42\n)\nrf.fit(X_train, y_train)\n\n# Get feature importances\nimportances = pd.DataFrame({'Feature': X_train.columns, 'Importance': rf.feature_importances_})\nimportances = importances.sort_values('Importance', ascending=False)\n\n# Print the top 10 most important features\nprint(importances.head(30))\n\nprint(f\"OOB score:\", rf.oob_score_)\n\n# Predict salaries on the test set and calculate RMSE and R-squared\npredictions = rf.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr_squared = r2_score(y_test, predictions)\nprint('RMSE:', rmse)\nprint('R-squared:', r_squared)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance\n\n## OOB Score:\n\nThe out-of-bag (OOB) score is an estimate of the model's performance on unseen data. It is calculated by randomly selecting a subset of the training data to build each decision tree in the random forest model. The remaining data that is not used to build the tree is called the \"out-of-bag\" data. The model can then be evaluated on this out-of-bag data to estimate its performance on unseen data. A higher OOB score indicates better performance of the model on unseen data.\n\n## Root Mean Squared Error (RMSE):\n\nThe root mean squared error (RMSE) is a measure of the difference between the predicted and actual values of the target variable. It is calculated as the square root of the average of the squared differences between the predicted and actual values. RMSE is often used as a metric for regression models. A lower RMSE score indicates better performance of the model in predicting the target variable.\n\n## R-squared:\n\nThe R-squared score (also known as the coefficient of determination) is a statistical measure that represents the proportion of variance in the dependent variable that is explained by the independent variables in the model. It ranges from 0 to 1, where 0 means the model does not explain any variance in the dependent variable, and 1 means the model explains all the variance in the dependent variable. R-squared is often used as a metric to evaluate the goodness of fit of regression models. A higher R-squared score indicates better performance of the model in explaining the variance in the dependent variable.\n\n## Summary:\n\nBased on the scores, we can evaluate the performance of the random forest model as follows:\n\n- OOB Score: The model has an OOB score of 0.410685359490081, indicating that it may not generalize well to unseen data.\n\n- RMSE: The RMSE score of the model is 0.40192550900112234, which means that, on average, the model's predictions are off by about $50,663.29. This score can be considered moderate to high, depending on the context.\n\n- R-squared: The R-squared score of the model is 0.37415958375830816, indicating that the model explains about 37.4% of the variance in the target variable. This score can be considered moderate, as it suggests that the model is not able to explain a large portion of the variance in the target variable.\n\nIt was found that changing the shown hyperparameters did not make much of a difference in performance even at extreme differences in tuning. Overall, while the model has some predictive power, it may not generalize well to unseen data in this cirucmstance, and there is still room for improvement in terms of reducing the error and increasing the amount of variance in the target variable explained by the model.","metadata":{}},{"cell_type":"markdown","source":"# Keras Neural Network\nThe model has four layers of dense neural networks with varying numbers of neurons and activation functions. It also includes dropout regularization to reduce overfitting. The model is compiled with mean squared error as the loss function and Adam as the optimizer. The model is then trained on training data and validated on testing data for 500 epochs with a batch size of 20. Finally, the root mean squared error is evaluated on the testing data and displayed. A learning curve plot of the training and validation loss is also generated using the history object obtained from training the model.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom keras import layers\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(Dense(128, input_shape=(256,), activation='relu'))\nlayers.Dropout(rate=0.2)\nmodel.add(Dense(64, activation='sigmoid'))\nlayers.Dropout(rate=0.2)\nmodel.add(Dense(1, activation = 'linear'))\n\n\n# Compile the model\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n#test and visualuze\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    batch_size=500,\n    epochs=500,\n)\n\nrmse = model.evaluate(X_test, y_test, verbose=0)\nprint('RMSE:', rmse)\n\n\n# Show the learning curves\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance \nIt seems that dummy encodings for all categorical variables is not an optimal solution to having categorical data, possible improvments could be including ordinal encoding for ordered features like experience level and company size. Upon review it seems that currency a person is paid in correlates to different salaries as well, so that has been added back into the dataset for further analysis. ","metadata":{}},{"cell_type":"markdown","source":"# Improving performance via feature engineering \n- dummy coding currency type\n- ordinal coding company size and employee experience","metadata":{}},{"cell_type":"code","source":"salaries_df = pd.read_csv('../input/data-science-salaries-2023/ds_salaries.csv')\n\n#dropping salary feature but keeping currency \nsalaries_df = salaries_df.drop('salary', axis=1)\n\ndummy_df = pd.get_dummies(salaries_df[['employment_type', 'job_title','employee_residence','company_location','salary_currency']], prefix=['time', 'job','resd','loc','curr'])\nfiltered_salaries_df = pd.concat([salaries_df, dummy_df], axis=1)\n\nfiltered_salaries_df = filtered_salaries_df.drop([ 'employment_type', 'job_title','employee_residence','company_location','salary_currency'], axis=1)\nfiltered_salaries_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ordinal encoding \nHere we are going to ordinal encode ordered features of company size and experience level to create a better dataset for the models ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\n\nencoder = OrdinalEncoder(categories=[['S', 'M', 'L']])\nencoder.fit(filtered_salaries_df[['company_size']])\nfiltered_salaries_df[['size_encoded']] = encoder.transform(filtered_salaries_df[['company_size']])\nfiltered_salaries_df = filtered_salaries_df.drop('company_size', axis=1)\nfiltered_salaries_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = OrdinalEncoder(categories=[['EN', 'MI', 'SE','EX']])\nencoder.fit(filtered_salaries_df[['experience_level']])\nfiltered_salaries_df[['exp_encoded']] = encoder.transform(filtered_salaries_df[['experience_level']])\nfiltered_salaries_df = filtered_salaries_df.drop('experience_level', axis=1)\nfiltered_salaries_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Model ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(filtered_salaries_df.drop('salary_in_usd', axis=1), filtered_salaries_df['salary_in_usd'], random_state=1)\n\n# Train a random forest regressor model\nn_estimators = 2000  # number of trees in the forest\nmax_depth = 300   # maximum depth of each decision tree\nmin_samples_split = 10 # minimum number of samples required to split an internal node\nmin_samples_leaf = 3   # minimum number of samples required to be at a leaf node\n\n# Create the Random Forest model with the desired hyperparameters\nrf = RandomForestRegressor(\n    n_estimators=n_estimators,\n    oob_score=True,\n    max_depth=max_depth,\n    min_samples_split=min_samples_split,\n    min_samples_leaf=min_samples_leaf,\n    random_state=42\n)\nrf.fit(X_train, y_train)\n\n# Get feature importances\nimportances = pd.DataFrame({'Feature': X_train.columns, 'Importance': rf.feature_importances_})\nimportances = importances.sort_values('Importance', ascending=False)\n\n# Print the top 10 most important features\nprint(importances.head(30))\n\nprint(f\"OOB score:\", rf.oob_score_)\n\n# Predict salaries on the test set and calculate RMSE and R-squared\npredictions = rf.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr_squared = r2_score(y_test, predictions)\nprint('RMSE:', rmse)\nprint('R-squared:', r_squared)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keras model ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom keras import layers\n\n# Define the model architecture\nmodel = Sequential()\nmodel.add(Dense(400, input_shape=(271,), activation='relu'))\nlayers.Dropout(rate=0.2)\nmodel.add(Dense(200, activation='relu'))\nlayers.Dropout(rate=0.2)\nmodel.add(Dense(100, activation='relu'))\nlayers.Dropout(rate=0.2)\nmodel.add(Dense(50, activation='relu'))\nlayers.Dropout(rate=0.2)\nmodel.add(Dense(10, activation='relu'))\nlayers.Dropout(rate=0.2)\nmodel.add(Dense(1, activation = 'linear'))\n\n\n# Compile the model\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n#test and visualuze\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    batch_size=20,\n    epochs=100,\n)\n\nrmse = model.evaluate(X_test, y_test, verbose=0)\nprint('RMSE:', rmse)\n\n\n# Show the learning curves\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nBased on these experiments, I found that random forest preforms well compared to a keras neural network on this data and that using different encoding methods for categorical features did not significantly affect the performance of Random Forest and Keras models on our dataset. However, it's important to note that the effectiveness of different encoding methods may vary depending on the specific dataset and the type of models used. In general, it's always a good idea to experiment with different encoding methods and model architectures to find the combination that works best for a given problem.","metadata":{}}]}